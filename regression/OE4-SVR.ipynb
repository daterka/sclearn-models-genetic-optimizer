{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykorzystanie biblioteki DEAP w problemie optymalizacji parametrów klasyfikatorów oraz selekcji cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Optymalizacja parametrów klasyfikatorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Epsilon-Support Vector Regression\n",
    "from sklearn import svm \n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import cross_val_score # perform cross-validation for estimator evaluation\n",
    "from sklearn.model_selection import cross_val_predict # generate cross-validated estimates for each input\n",
    "from sklearn.model_selection import train_test_split # splits arrays/matrices into random train and test subsets\n",
    "from sklearn.model_selection import GridSearchCV # determines estimator paremeters values\n",
    "from sklearn.model_selection import StratifiedKFold # stratified k-fold cross-validator\n",
    "from sklearn.model_selection import KFold # k-fold cross-validator\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "\n",
    "# feature selection based on weights importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# rest\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landAvg_1_PriorYear</th>\n",
       "      <th>landAvg_2_PriorYear</th>\n",
       "      <th>landAvg_3_PriorYear</th>\n",
       "      <th>landAvg_4_PriorYear</th>\n",
       "      <th>landMax_2_PriorYear</th>\n",
       "      <th>landMax_5_PriorYear</th>\n",
       "      <th>landMin_4_PriorYear</th>\n",
       "      <th>land&amp;OceanAvg_1_PriorYear</th>\n",
       "      <th>land&amp;OceanAvg_2_PriorYear</th>\n",
       "      <th>oceanAvg_1_PriorYear</th>\n",
       "      <th>oceanAvg_2_PriorYear</th>\n",
       "      <th>oceanAvg_5_PriorYear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850-01-01</th>\n",
       "      <td>-1.344498</td>\n",
       "      <td>-1.343748</td>\n",
       "      <td>-1.342076</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>-1.404913</td>\n",
       "      <td>-1.403688</td>\n",
       "      <td>-1.277205</td>\n",
       "      <td>-1.177569</td>\n",
       "      <td>-1.176354</td>\n",
       "      <td>1.528022</td>\n",
       "      <td>1.528980</td>\n",
       "      <td>1.529537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851-01-01</th>\n",
       "      <td>-1.344498</td>\n",
       "      <td>-1.343748</td>\n",
       "      <td>-1.342076</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>-1.404913</td>\n",
       "      <td>-1.403688</td>\n",
       "      <td>-1.277205</td>\n",
       "      <td>-1.177569</td>\n",
       "      <td>-1.176354</td>\n",
       "      <td>1.528022</td>\n",
       "      <td>1.528980</td>\n",
       "      <td>1.529537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852-01-01</th>\n",
       "      <td>-1.439527</td>\n",
       "      <td>-1.343748</td>\n",
       "      <td>-1.342076</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>-1.404913</td>\n",
       "      <td>-1.403688</td>\n",
       "      <td>-1.277205</td>\n",
       "      <td>-1.543883</td>\n",
       "      <td>-1.176354</td>\n",
       "      <td>1.233484</td>\n",
       "      <td>1.528980</td>\n",
       "      <td>1.529537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853-01-01</th>\n",
       "      <td>-1.452432</td>\n",
       "      <td>-1.438803</td>\n",
       "      <td>-1.342076</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>-1.250940</td>\n",
       "      <td>-1.403688</td>\n",
       "      <td>-1.277205</td>\n",
       "      <td>-1.554889</td>\n",
       "      <td>-1.543128</td>\n",
       "      <td>1.248574</td>\n",
       "      <td>1.234485</td>\n",
       "      <td>1.529537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854-01-01</th>\n",
       "      <td>-1.590870</td>\n",
       "      <td>-1.451711</td>\n",
       "      <td>-1.437103</td>\n",
       "      <td>-1.341202</td>\n",
       "      <td>-1.361717</td>\n",
       "      <td>-1.403688</td>\n",
       "      <td>-1.277205</td>\n",
       "      <td>-1.624064</td>\n",
       "      <td>-1.554147</td>\n",
       "      <td>1.479957</td>\n",
       "      <td>1.249573</td>\n",
       "      <td>1.529537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            landAvg_1_PriorYear  landAvg_2_PriorYear  landAvg_3_PriorYear  \\\n",
       "date                                                                        \n",
       "1850-01-01            -1.344498            -1.343748            -1.342076   \n",
       "1851-01-01            -1.344498            -1.343748            -1.342076   \n",
       "1852-01-01            -1.439527            -1.343748            -1.342076   \n",
       "1853-01-01            -1.452432            -1.438803            -1.342076   \n",
       "1854-01-01            -1.590870            -1.451711            -1.437103   \n",
       "\n",
       "            landAvg_4_PriorYear  landMax_2_PriorYear  landMax_5_PriorYear  \\\n",
       "date                                                                        \n",
       "1850-01-01            -1.341202            -1.404913            -1.403688   \n",
       "1851-01-01            -1.341202            -1.404913            -1.403688   \n",
       "1852-01-01            -1.341202            -1.404913            -1.403688   \n",
       "1853-01-01            -1.341202            -1.250940            -1.403688   \n",
       "1854-01-01            -1.341202            -1.361717            -1.403688   \n",
       "\n",
       "            landMin_4_PriorYear  land&OceanAvg_1_PriorYear  \\\n",
       "date                                                         \n",
       "1850-01-01            -1.277205                  -1.177569   \n",
       "1851-01-01            -1.277205                  -1.177569   \n",
       "1852-01-01            -1.277205                  -1.543883   \n",
       "1853-01-01            -1.277205                  -1.554889   \n",
       "1854-01-01            -1.277205                  -1.624064   \n",
       "\n",
       "            land&OceanAvg_2_PriorYear  oceanAvg_1_PriorYear  \\\n",
       "date                                                          \n",
       "1850-01-01                  -1.176354              1.528022   \n",
       "1851-01-01                  -1.176354              1.528022   \n",
       "1852-01-01                  -1.176354              1.233484   \n",
       "1853-01-01                  -1.543128              1.248574   \n",
       "1854-01-01                  -1.554147              1.479957   \n",
       "\n",
       "            oceanAvg_2_PriorYear  oceanAvg_5_PriorYear  \n",
       "date                                                    \n",
       "1850-01-01              1.528980              1.529537  \n",
       "1851-01-01              1.528980              1.529537  \n",
       "1852-01-01              1.528980              1.529537  \n",
       "1853-01-01              1.234485              1.529537  \n",
       "1854-01-01              1.249573              1.529537  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "import pandas as pd\n",
    "\n",
    "%store -r predictors_x\n",
    "%store -r outcomes_y\n",
    "\n",
    "predictors_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landAvg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850-01-01</th>\n",
       "      <td>-1.834912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851-01-01</th>\n",
       "      <td>-1.440372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852-01-01</th>\n",
       "      <td>-1.453273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853-01-01</th>\n",
       "      <td>-1.591667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854-01-01</th>\n",
       "      <td>-1.710123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             landAvg\n",
       "date                \n",
       "1850-01-01 -1.834912\n",
       "1851-01-01 -1.440372\n",
       "1852-01-01 -1.453273\n",
       "1853-01-01 -1.591667\n",
       "1854-01-01 -1.710123"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(predictors_x, outcomes_y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1792, 12), (1792, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 12), (200, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "numberOfAtributtes= len(x_train.columns)\n",
    "print(numberOfAtributtes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9917577580935905\n"
     ]
    }
   ],
   "source": [
    "# Classification using SVC with default parameters and 5x K-fold cross validation for all 45 features\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y=y_train.values.ravel()\n",
    "df = df_norm=x_train.values\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "pipe.fit(df, y)\n",
    "scores = pipe.score(x_test.values, y_test.values.ravel())\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generationg new individual\n",
    "import random\n",
    "def parametersSVR(numberFeatures,icls):\n",
    "    genome = list()\n",
    "\n",
    "    #kernel\n",
    "    listKernel = [\"linear\",\"rbf\", \"poly\",\"sigmoid\"]\n",
    "    genome.append(listKernel[random.randint(0, 3)])\n",
    "\n",
    "    #c\n",
    "    k = random.uniform(0.1, 100)\n",
    "    genome.append(k)\n",
    "\n",
    "    #degree\n",
    "    genome.append(random.uniform(0.1,5))\n",
    "\n",
    "    #gamma\n",
    "    gamma = random.uniform(0.001,5)\n",
    "    genome.append(gamma)\n",
    "\n",
    "    # coeff\n",
    "    coeff = random.uniform(0.01, 10)\n",
    "    genome.append(coeff)\n",
    "\n",
    "    return icls(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation\n",
    "def mutationSVR(individual):\n",
    "    numberParamer= random.randint(0,len(individual)-1)\n",
    "    if numberParamer==0:\n",
    "        # kernel\n",
    "        listKernel = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "        individual[0]=listKernel[random.randint(0, 3)]\n",
    "    elif numberParamer==1:\n",
    "        #C\n",
    "        k = random.uniform(0.1,100)\n",
    "        individual[1]=k\n",
    "    elif numberParamer == 2:\n",
    "        #degree\n",
    "        individual[2]=random.uniform(0.1, 5)\n",
    "    elif numberParamer == 3:\n",
    "        #gamma\n",
    "        gamma = random.uniform(0.01, 5)\n",
    "        individual[3]=gamma\n",
    "    elif numberParamer ==4:\n",
    "        # coeff\n",
    "        coeff = random.uniform(0.1, 20)\n",
    "        individual[2] = coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def parametersFitnessSVR(y,df,numberOfAtributtes,individual):\n",
    "    split=5\n",
    "    kf = KFold(n_splits=split)\n",
    "    df_norm = df\n",
    "\n",
    "    estimator = SVR(kernel=individual[0],C=individual[1],degree=individual[2],\n",
    "                    gamma=individual[3],coef0=individual[4])\n",
    "    resultSum = 0\n",
    "    counter = 0\n",
    "    for train, test in kf.split(df_norm):\n",
    "        estimator.fit(df_norm[train], y[train])\n",
    "        predicted = estimator.predict(df_norm[test])\n",
    "        expected = y[test]\n",
    "        resultSum=estimator.score(df_norm[test], y[test])\n",
    "        counter+=1\n",
    "    return resultSum/counter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools\n",
    "import random\n",
    "from math import sin\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizePopulation = 100\n",
    "probabilityMutation = 0.2\n",
    "probabilityCrossover = 0.8\n",
    "numberIteration = 100\n",
    "numberElitism = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configureDeap(fitness, parameters, mutation,\n",
    "                  selection_param={'function':tools.selTournament, 'tournsize':3},\n",
    "                 mate_params={'function':tools.cxTwoPoint},):\n",
    "    \n",
    "    creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox() \n",
    "    toolbox.register('individual', parameters, numberOfAtributtes, creator.Individual)\n",
    "    toolbox.register('evaluate', fitness,y,df,numberOfAtributtes)\n",
    "    toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register('select', **selection_param)\n",
    "    toolbox.register('mate', **mate_params)\n",
    "    toolbox.register('mutate', mutation)\n",
    "\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(toolbox, offspring):\n",
    "    for mutant in offspring:\n",
    "        # mutation\n",
    "        if random.random() < probabilityMutation:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setIndividualFitnessValue(individuals, fitnesses):\n",
    "    for ind, fit in zip(individuals, fitnesses):\n",
    "        ind.fitness.value = [fit]\n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initPopulation(toolbox):\n",
    "    population = toolbox.population(n=sizePopulation)\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    population = setIndividualFitnessValue(population, fitnesses)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(toolbox, offspring):\n",
    "    # [::2] - gets only individuals with odd indexes\n",
    "    # [1::2] -  gets only individuals with even indexes\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        # crossover\n",
    "        if random.random() < probabilityCrossover:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(toolbox, offspring, verbose=0):\n",
    "    # evaluate new individuals\n",
    "    new_individuals = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    new_fitnesses = map(toolbox.evaluate, new_individuals)\n",
    "    for ind, fit in zip(new_individuals, new_fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    if verbose>3:\n",
    "        print('Ewaluated %i individuals'%len(new_individuals))\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestsForElitism(population):\n",
    "    listElitism = []\n",
    "    for x in range(0, numberElitism):\n",
    "        listElitism.append(tools.selBest(population, 1)[0])\n",
    "    return listElitism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateStatistics(population,verbose=0):\n",
    "    fits = [ind.fitness.values[0] for ind in population]\n",
    "    length = len(population)\n",
    "    mean = sum(fits)/length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2/length-mean **2)**0.5\n",
    "    if verbose>2:\n",
    "        print(\"  Min %s\" % min(fits))\n",
    "        print(\"  Max %s\" % max(fits))\n",
    "        print(\"  Avg %s\" % mean)\n",
    "        print(\"  Std %s\" % std)\n",
    "    return (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickBestIndividual(population, verbose=0):\n",
    "    best_ind = tools.selBest(population, 1)[0]\n",
    "    if verbose>1:\n",
    "        print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "    return best_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSimple(y_vals=[], label_y='y', label_x='x', title='plot', instance_info='no_info', save_location='./plots/'):\n",
    "    filename = save_location + title+'_'+ instance_info +'.png'\n",
    "    x_vals = [x for x in range(len(y_vals))]\n",
    "    plt.plot(x_vals, y_vals)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(label_y)\n",
    "    plt.xlabel(label_x)\n",
    "#     plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(stats):\n",
    "    plotSimple([best[0].fitness.values[0] for best in stats], 'best', 'epoch', 'fitness(iteration)')\n",
    "    plotSimple([best[1] for best in stats], 'mean', 'epoch', 'mean(iteration)')\n",
    "    plotSimple([best[2] for best in stats], 'std', 'epoch', 'std(iteration)')\n",
    "    plotSimple([best[3] for best in stats], 'duration', 'epoch', 'epoch_duration(iteration)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startOptimizationLoop(toolbox, population, elitism=False, verbose=0):\n",
    "    stats = []\n",
    "    g = 0\n",
    "    while g < numberIteration:\n",
    "        g = g + 1\n",
    "        if verbose>0:\n",
    "            print('-- Generation %i --' % g)\n",
    "        start = timer()  \n",
    "        offspring = toolbox.select(population, len(population))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "        elite = getBestsForElitism(offspring) if elitism else []\n",
    "        \n",
    "        offspring = crossover(toolbox, offspring)\n",
    "        offspring = mutate(toolbox, offspring)\n",
    "        offspring = evaluate(toolbox, offspring)\n",
    "        duration = timer()-start\n",
    "        \n",
    "        population[:] = offspring + elite\n",
    "\n",
    "        mean, std = calculateStatistics(population, verbose)\n",
    "        best_ind = pickBestIndividual(population, verbose)\n",
    "        stats.append((best_ind, mean, std, duration))\n",
    "    \n",
    "    if verbose>-1:\n",
    "        best_overall = pickBestIndividual(population, verbose)\n",
    "        print('Best found individual: (x1,x2) =', best_overall, ', y =', best_overall.fitness.values[0])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fitness, parameters, mutation, selection, mate, elitism, verbose):\n",
    "    toolbox = configureDeap(fitness, parameters, mutation, selection, mate)\n",
    "    population = initPopulation(toolbox)\n",
    "    stats = startOptimizationLoop(toolbox, population, elitism, verbose)\n",
    "    plotResults(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 0 (tournament, cxTwoPoint, with elitism):\n",
    "selection={'function':tools.selTournament, 'tournsize':3} \n",
    "mate={'function':tools.cxTwoPoint}\n",
    "\n",
    "parameters=parametersSVR\n",
    "fitness=parametersFitnessSVR\n",
    "mutation=mutationSVR\n",
    "elitism = False\n",
    "verbose = 7\n",
    "run(fitness, parameters, mutation, selection , mate , elitism, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = ['poly', 0.3690320297276768, 1.9084110197644817, 0.1053757953826651, 8.515094980694283]\n",
    "print(SVCParametersFitness(y,df,numberOfAtributtes,ind))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Selekcja cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVCParametersFeatureFitness(y,df,numberOfAtributtes,individual):\n",
    "    split=5\n",
    "    cv = StratifiedKFold(n_splits=split)\n",
    "    \n",
    "    listColumnsToDrop=[] #lista cech do usuniecia\n",
    "    for i in range(numberOfAtributtes,len(individual)):\n",
    "            if individual[i]==0: #gdy atrybut ma zero to usuwamy cechę\n",
    "                listColumnsToDrop.append(i-numberOfAtributtes)\n",
    "\n",
    "    dfSelectedFeatures=df.drop(df.columns[listColumnsToDrop], axis=1, inplace=False)\n",
    "    \n",
    "    mms = MinMaxScaler()\n",
    "    df_norm = mms.fit_transform(dfSelectedFeatures)\n",
    "    estimator = SVC(kernel=individual[0],C=individual[1],degree=individual[2],gamma=individual[3],coef0=individual[4],random_state=101)\n",
    "    resultSum = 0\n",
    "    for train, test in cv.split(df_norm, y):\n",
    "        estimator.fit(df_norm[train], y[train])\n",
    "        predicted = estimator.predict(df_norm[test])\n",
    "        expected = y[test]\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(expected, predicted).ravel()\n",
    "        result = (tp + tn) / (tp + fp + tn + fn) #w oparciu o macierze pomyłek https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "        resultSum = resultSum + result #zbieramy wyniki z poszczególnych etapów walidacji krzyżowej\n",
    "\n",
    "    return resultSum / split,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutationFeatureSVC(individual):\n",
    "    numberParamer= random.randint(0,len(individual)-1)\n",
    "    if numberParamer==0:\n",
    "        # kernel\n",
    "        listKernel = [\"linear\", \"rbf\", \"poly\", \"sigmoid\"]\n",
    "        individual[0]=listKernel[random.randint(0, 3)]\n",
    "    elif numberParamer==1:\n",
    "        #C\n",
    "        k = random.uniform(0.1,100)\n",
    "        individual[1]=k\n",
    "    elif numberParamer == 2:\n",
    "        #degree\n",
    "        individual[2]=random.uniform(0.1, 5)\n",
    "    elif numberParamer == 3:\n",
    "        #gamma\n",
    "        gamma = random.uniform(0.01, 1)\n",
    "        individual[3]=gamma\n",
    "    elif numberParamer ==4:\n",
    "        # coeff\n",
    "        coeff = random.uniform(0.1, 1)\n",
    "        individual[2] = coeff\n",
    "    else: #genetyczna selekcja cech\n",
    "        if individual[numberParamer] == 0: \n",
    "            individual[numberParamer] = 1\n",
    "        else:\n",
    "            individual[numberParamer] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario 0 (tournament, mutGaussian, cxTwoPoint, with elitism):\n",
    "selection={'function':tools.selTournament, 'tournsize':3} \n",
    "mutation={'function':mutationFeatureSVC}\n",
    "# mutation={'function':tools.mutGaussian, 'mu':0.0, 'sigma':0.2, 'indpb':0.2}\n",
    "mate={'function':tools.cxTwoPoint}\n",
    "fitness=SVCParametersFeatureFitness\n",
    "elitism = False\n",
    "verbose = 0\n",
    "run(selection, mutation, mate, fitness, elitism, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
